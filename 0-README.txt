#######################################################################################################################
# Before starting
#######################################################################################################################

Install executables for trimming/mapping and include these in the user PATH so they can be run from the command line 
- trimgalore * not used in current version
- cutadapt   * not used in current version
- FastQC
- makeblastdb
- blastn
- magicblast
- samtools

Install/update the following R packages.

source("http://bioconductor.org/biocLite.R")
biocLite()
install.packages("ShortRead")
install.packages("Biostrings")
install.packages("GenomicAlignments")

Create a series of directories for running bcl2fastq and the trimming/mapping/analysis e.g.

~/Illumina/data/input     the files from the sequencing run
~/Illumina/data/output    the output folder for the fastq files generated by bcl2fastq
~/Illumina/M-1-24         the working directory containing the R and UNIX shell scripts
~/Illumina/M-1-24/Reads   the project directory containing the reads
~/Illumina/Genomes        the directory containing the fasta genomes for mapping as well as the databases derived from these

#######################################################################################################################
# Create blast databases
#######################################################################################################################

Make a blast database for the genome being used.
makeblastdb -in <reference.fa> -dbtype nucl -parse_seqids -out <database_name> -title "Database title"
e.g. makeblastdb -in mm10.fa -dbtype nucl -parse_seqids -out mm10 -title "mm10"
e.g. makeblastdb -in hg38.fa -dbtype nucl -parse_seqids -out hg38 -title "hg38"

Make a blast database for the insert sequence (to identify reads mapping to internal regions of the insert seq)
e.g. makeblastdb -in MuLV.fa -dbtype nucl -parse_seqids -out MuLV -title "MuLV"
e.g. makeblastdb -in Lenti.fa -dbtype nucl -parse_seqids - out Lenti -title "Lenti"

Place fasta files and their database files in the folder ../Genomes relative to the working directory.
e.g. ~/Illumina/Genomes


#######################################################################################################################
# Run bcl2fastq to create custom fastq files and demultiplex
#######################################################################################################################

Backup the SampleSheet.csv file present in the sequencing run folder. Remove NNNNNNNN UMI residues from the indexes.

Copy the contents of the sequencing run including the modified sample sheet to 

~/Illumina/data/input 

Run bcl2fastq with the custom parameters e.g.

bcl2fastq 
-R ~/Illumina/data/input 
-o ~/Illumina/data/output 
--sample-sheet ~/Illumina/data/input/SampleSheet.csv 
--barcode-mismatches 0,0 
--use-bases-mask y*n,I10,I10y*,y*n 
--mask-short-adapter-reads 4 
--no-lane-splitting 
--ignore-missing-bcl 
--create-fastq-for-index-reads  &> ~/Illumina/data/output/bcl2fastq.log

On non linux systems bcl2fastq can be run as a docker volume https://docs.docker.com/app/working-with-app/ e.g.

docker run --rm 
-v ~/Illumina/data/input:~/Illumina/data/input:ro 
-v ~/Illumina/data/output:~/Illumina/data/output 
umccr/bcl2fastq 
-R ~/Illumina/data/input 
-o ~/Illumina/data/output 
--sample-sheet ~/Illumina/data/input/SampleSheet.csv 
--barcode-mismatches 0,0 
--use-bases-mask y*n,I10,I10y*,y*n 
--mask-short-adapter-reads 4 
--no-lane-splitting 
--ignore-missing-bcl 
--create-fastq-for-index-reads  &> ~/Illumina/data/output/bcl2fastq.log

Fastq files will be produced in the output folder.


#######################################################################################################################
# Prepare sample_table.txt
#######################################################################################################################


Prepare "sample_table.txt" tab separated file based partly on information present in the illumina sample sheet 
and including additional fields e.g. 

Field                     Example
run_id                    '1'
sample_id                 'M-1'
tissue                    '5036 spleen'
animal_id                 '5036'
genome                    'mm10'
replicate_group           '1'
overlap_groups            '1'
i7_primer_index_name      'I1030'
i7_index                  'TCAAATGGCC'
i5_adapt_index_name       'I1251'
i5_index                  'GGTAGTGGTA'
seq_insert_bases          'GGTCTTTCA'
PCR_insert_bases          'GGTCTTTCA'
primer_seq_i5_r2_end      'CAAGCAGAAGACGGCATACGAGATGGCCATTTGAGCTAGCTTGCCAAACCTACAGGTGG'
adapter_seq_i7_r1_UMI_end 'AATGATACGGCGACCACCGAGATCTACACGGTAGTGGTANNNNNNNNNNGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'

Field                      Explanation                                       
seq_insert_bases           -bases between the read2 sequencing primer and the insert-genome junction
PCR_insert_bases           -bases between the insert end secondary PCR primer and the insert-genome junction 
                            (these might be but are not necessarily the same as seq_insert_bases)
primer_seq_i5_r2_end       -the secondary PCR primer from the including the index
adapter_seq_i7_r1_UMI_end  -the sequence of the adapter running from the 5' exterior of the fragment including the index 

- samples originating from the same DNA sample are assigned to a "replicate_group".
- samples originating from DNAs that are expected to share inserts (different DNAs from the same tissue or animal or
DNA samples that have been mixed) are assigned one or more "overlap_groups" 
e.g. a mixture of DNA1 & DNA2 belongs to "overlap_group" "1+2"
- control DNAs are given replicate_group and overlap_group value of 0

#######################################################################################################################
# Set up the working directory
#######################################################################################################################

Copy all .sh and .R scripts to the working directory as well as the sample_table.txt file.

1-Trim.R
1-Trim.sh
2-Map.R
2-Map.sh
3-Inserts.R
3-Inserts.sh
4-Duplicates.R

Move fastq files for all samples to a directory called Reads inside the working directory.
e.g. ~/Illumina/M-1-24/Reads

Rename the files for read 2 to read 3 and vice versa.

mmv '*_R2_*' '#1_R4_#2'
mmv '*_R3_*' '#1_R2_#2'
mmv '*_R4_*' '#1_R3_#2'

If any reads fastq files derive from more than one sequencing run these files should be concatenated.

#######################################################################################################################
# 1 - Trimming
#######################################################################################################################
Trimming of adapter and PCR primer sequences from the 3' ends of read 1 and 2 uses blastn and a list of custom 
sequences present in the sample_sheet.txt file. The speed of this trimming depends primarily on the word_size parameter
given to blastn which can be set in the R script 1-Trim.R as low as 4 for a few thousand reads per sample up to the 
lower sensitivity default value of 16 when processing hundreds of thousands of reads per sample.

From the project directory run the shell script 1-Trim.sh which calls the R script 1-Trim.R which

- runs fastqc and saves the files in the directory ./FastQC
- calls the R script 1-Trim.R which

- imports all reads (1,2 & 3) from ./Reads into a reads table dataframe.
- removes reads that don't have the expected insert-genome junction bases at the beginning of read 2.
- uses blastn to identify insert and adapter sequences at the 3' end of read 1 and read 2 respectively.
- only keeps trimming within a specified number of bases from the adapter/primer end with a bitscore cutoff. 
The ideal criteria can vary depending on read quality and length of primers used. The results can be reviewed 
by uncommenting lines 190 - 206, 241 - 250 and altering parameters after reviewing the output.
 For MuLV read 1 & 2 we use > 16 bases from the adapter/primer end and a bitscore > 14.
 For Lentivirus read 1 & 2 we use > 16 bases from the adapter/primer end and a bitscore > 14.
 For piggyBac read 1 we use > 30 bases from the adapter/primer end and a bitscore > 14.
 For piggyBac read 2 we use > 30 bases from the adapter/primer end and a bitscore > 24.
 
- identifies reads that have the expected bases corresponding to the insert prior to the insert-genome junction.
- writes trimmed fastq files that have removed these sequences to the directory ./Trimmed
- saves the dataframe containing the reads as an RData file in the directory ./Tables


#######################################################################################################################
# 2 - Mapping
#######################################################################################################################
From the working directory run the shell script 2-Map.sh which calls the R script 2-Map.R which

- loads the trimmed read fastq files from ./Trimmed and loads the reads table RData file.
- maps them using magicblast against the insert sequence (specified in the shell script e.g. "MuMLV", "Lenti")
- maps them using magicblast against the genome sequence (specified in the shell script e.g. "mm10, "hg38")
- runs samtools to create paired sam/bam files and indexed bam files and saves them in the directory ./Mapping
- loads the paired bam files records the coordinates, strand and cigar string of mapped reads and saves to ./Mapping
- labels which read pairs map to the genome or to the insert (or both)
- adds the mapping coordinates to the master table and saves the table to ./Mapping


#######################################################################################################################
# 3 - Inserts
#######################################################################################################################
From the working directory run the shell script 3-Inserts.sh which calls the R script 3-Inserts.R which

- loads the reads table including mapping coordinates.
- finds reads mapping with to the same coordinates and orientation and these are clustered (within 10bp) to form inserts.
- if UMI sequences are identical between two different inserts these are removed.
- the UMI sequences, read numbers and fragment lengths for each read are recorded for each insert.
- UMI sequences that only differ by 1bp (i.e. Hamming distance 1) are collapsed/grouped.
- the reads, unique sheared fragment ends, collapsed UMIs and unique UMIs are counted for each insert.
- if reads clustered to form an insert have more than one insert-genome junction the most abundant position is chosen.
- a unique string for each insert consisting of the sample id, chromosome, strand and position is recorded.
- clonality and normalized clonality values for each insert are calculated.

The remaining list of intermediate RData files in ./Tables can be backed up or deleted.
Only insert_table.RData will be used for further analysis.

*_reads_table.RData
*_reads_table_trim.RData
*_R1_insert_trim.RData
*_R2_insert_trim.RData
*_mapping.RData
*_mapped_reads_table.RData
*_good_reads_table.RData
*_grouped_reads.RData
*_insert_table_long.RData
*_insert_table.RData


#######################################################################################################################
# 4 - Duplicates
#######################################################################################################################
From the working directory run the R script 4-Duplicates.R which
- loads sample_table.txt which contains details of each sample origin 
(sample_id, sample_description, DNA_id, tissue_id, animal_id, genome, replicate_group, overlap_group).
- loads the *insert_table.RData files of all samples and concatenates them into a single table.
- for each chromosome all inserts that map to the same strand and position are identified/clustered by distance matrix.
- duplicate inserts from multiple samples are given a unique "duplicate_id".
- duplicate inserts present in the control samples are flagged in the "control" column.
- duplicate inserts present only within the expected replicate groups "DNA_replicate", "tissue", "organism" are flagged 
in the "expected" column.
- duplicate inserts present in samples that are not controls but not expected to share integrations (e.g two independent
organisms or biological replicates) are flagged in the "unexpected"
- the entropy scores and plots are calculated using the 50 most abundant inserts

#######################################################################################################################
# 5 - Filtering
#######################################################################################################################
Filtering can be done manually by opening the final table in excel and sorting the flagged columns.

- the simplest filtering is to remove any/all inserts flagged in the control column because this is evidence of 
mispriming or cross contamination between the DNA samples or during library preparation/PCR steps.

- all inserts in the "unexpected" column can be removed however for some regions of the genome with a very 
high density of integrations this may need to be manually revised e.g. in MuLV screens the Mycn 3' UTR has a very high
density of identical integrations that don't derived from cross contamination. Sequences for a give position can be
excluded from filtering by sorting using the "unexpected flat" then the "duplicate_group_id".

- examining the *_insert_table_long.RData which records the UMI sequences of the replicate inserts may be useful in 
identifying cross contamination that has occurred after the ligation step or where previous PCR products have 
contaminated a newer batch of libraries.





